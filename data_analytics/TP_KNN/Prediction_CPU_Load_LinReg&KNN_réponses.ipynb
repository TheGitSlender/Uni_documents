{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9efc6a0",
   "metadata": {},
   "source": [
    "\n",
    "# TP – Prédire le taux d’utilisation CPU d’un serveur à partir d’indicateurs réseau\n",
    "\n",
    "**Objectif pédagogique :** construire, expliquer et évaluer un modèle de **régression** qui anticipe la **charge CPU** d’un serveur à partir d’indicateurs réseau, comme on le ferait dans un **SOC (Security Operations Center)** pour détecter des surcharges (ex. DDoS) et comportements anormaux.\n",
    "\n",
    "## Plan\n",
    "1. Contexte de l’étude  \n",
    "2. Importations & données (simulation réaliste)  \n",
    "3. Exploration & pré‑traitement  \n",
    "   - Aperçu & valeurs manquantes  \n",
    "   - Analyse de corrélation  \n",
    "   - Encodage (rappel) & Standardisation  \n",
    "4. Train/Test split  \n",
    "5. Sélection séquentielle de variables (**SequentialFeatureSelector**)  \n",
    "6. Ajustement du modèle (régression linéaire) et évaluation  \n",
    "7. Amélioration par interactions (**PolynomialFeatures**) et ré‑évaluation  \n",
    "8. Recommandations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === IMPORTS ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bedcc",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Données : simulation réaliste (logs réseau)\n",
    "Dans un contexte SOC, on observe par **intervalle de temps** :\n",
    "- `tcp_connections` : nb de connexions TCP actives  \n",
    "- `data_volume_MB` : volume transmis (Mo)  \n",
    "- `packet_loss_rate` : taux de perte de paquets (%)  \n",
    "- `ids_alerts` : nb d’alertes IDS  \n",
    "- `cpu_load` : charge CPU (cible à prédire)\n",
    "\n",
    "> Ici, on **simule** un jeu de données cohérent avec du bruit pour pratiquer la modélisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3fd9f",
   "metadata": {},
   "source": [
    "\n",
    "# Génération de données synthétiques (reproductibles)\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"tcp_connections\": np.random.randint(50, 2000, n),\n",
    "    \"data_volume_MB\": np.random.uniform(100, 10000, n),\n",
    "    \"packet_loss_rate\": np.random.uniform(0, 5, n),   # en %\n",
    "    \"ids_alerts\": np.random.randint(0, 50, n)\n",
    "})\n",
    "\n",
    "# Relation linéaire + bruit\n",
    "noise = np.random.normal(0, 5, n)\n",
    "data[\"cpu_load\"] = (\n",
    "    0.02 * data[\"tcp_connections\"]\n",
    "    + 0.003 * data[\"data_volume_MB\"]\n",
    "    + 1.5 * data[\"packet_loss_rate\"]\n",
    "    + 0.3 * data[\"ids_alerts\"]\n",
    "    + 0.000005 * data[\"data_volume_MB\"]*data[\"tcp_connections\"]\n",
    "    + noise\n",
    ")\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92790b39",
   "metadata": {},
   "source": [
    "data.to_csv(\"G:\\Mon Drive\\ADD\\CS2C-Cybersecurity Data Analytics\\TDs-TPs\\cpu_load_data_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572261d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"cpu_load_data_.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e8a0b",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Exploration & pré‑traitement\n",
    "### 3.1 Aperçu général & qualité des données\n",
    "- Vérifier formats, valeurs manquantes, statistiques descriptives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09616e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a5658",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Analyse de corrélation\n",
    "- But : estimer la **force des relations linéaires** entre variables.  \n",
    "- Outil : matrice des corrélations de Pearson.  \n",
    "> **Rappel :** La corrélation ≠ causalité ; elle guide le choix de variables et l'interprétation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Matrice de corrélation\n",
    "corr = data.corr(numeric_only=True)\n",
    "\n",
    "# Visualisation avec matplotlib (pas de seaborn, 1 plot par figure, couleurs par défaut)\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(corr.values, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title(\"Matrice de corrélation (Pearson)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2844c1",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 Encodage des variables qualitatives (rappel)\n",
    "Si vous aviez des colonnes **catégorielles** (`type_proto`, `zone`, etc.), utilisez `pd.get_dummies(..., drop_first=True)` ou `OneHotEncoder`.  \n",
    "Ici, toutes les variables sont **numériques**, donc pas d’encodage à faire.\n",
    "\n",
    "### 3.4 Standardisation\n",
    "- Les variables sont sur des **échelles différentes** (Mo, %, compte…).  \n",
    "- On **standardise** pour améliorer la stabilité de l’entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns=[\"cpu_load\"])\n",
    "y = data[\"cpu_load\"].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Garder les noms de features pour le suivi\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d6deb",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Train/Test split\n",
    "On sépare les données pour **évaluer la généralisation** du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb072b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b050f43",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Sélection séquentielle de variables (**SequentialFeatureSelector**)\n",
    "**Idée :** choisir automatiquement un sous‑ensemble pertinent de variables pour limiter la complexité et le sur‑ajustement.\n",
    "\n",
    "- `direction=\"forward\"` : on **ajoute** les variables les plus utiles une à une  \n",
    "- `n_features_to_select=3` (modifiable pour expérimenter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linreg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(linreg, n_features_to_select=3, direction=\"forward\")\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "support_mask = sfs.get_support()\n",
    "selected_features = [name for name, keep in zip(feature_names, support_mask) if keep]\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242d4ac",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Ajustement du modèle linéaire & évaluation\n",
    "On ajuste la **régression linéaire** avec les **variables sélectionnées**, puis on évalue sur le **jeu de test**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrer les colonnes sélectionnées\n",
    "X_train_sfs = X_train[:, support_mask]\n",
    "X_test_sfs  = X_test[:, support_mask]\n",
    "\n",
    "linreg.fit(X_train_sfs, y_train)\n",
    "y_pred = linreg.predict(X_test_sfs)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE  : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nuage réel vs prédit (1 figure, pas de style/couleurs spécifiques)\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "min_v = min(y_test.min(), y_pred.min())\n",
    "max_v = max(y_test.max(), y_pred.max())\n",
    "plt.plot([min_v, max_v], [min_v, max_v], linestyle=\"--\")\n",
    "plt.xlabel(\"Valeurs réelles (CPU load)\")\n",
    "plt.ylabel(\"Valeurs prédites\")\n",
    "plt.title(\"Régression linéaire – Réel vs Prédit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb63f4f",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Amélioration : interactions (**PolynomialFeatures**)\n",
    "Les **interactions** (produits entre variables) modélisent des effets combinés (ex. trafic élevé × pertes de paquets).  \n",
    "Ici, on génère toutes les **caractéristiques polynomiales de degré 2** (sans biais), puis on ré‑entraîne un modèle linéaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
    "    X_poly, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "linreg_poly = LinearRegression()\n",
    "linreg_poly.fit(X_train_p, y_train_p)\n",
    "y_pred_p = linreg_poly.predict(X_test_p)\n",
    "\n",
    "mae_p  = mean_absolute_error(y_test_p, y_pred_p)\n",
    "rmse_p = mean_squared_error(y_test_p, y_pred_p) ** 0.5\n",
    "r2_p   = r2_score(y_test_p, y_pred_p)\n",
    "\n",
    "print(f\"MAE (poly)  : {mae_p:.2f}\")\n",
    "print(f\"RMSE (poly) : {rmse_p:.2f}\")\n",
    "print(f\"R² (poly)   : {r2_p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des coefficients du modèle polynomial\n",
    "pd.DataFrame({\"Variables\": poly.get_feature_names_out(input_features=X.columns).tolist(), \n",
    "             \"Coef\": linreg_poly.coef_}).sort_values(by=\"Coef\", key=abs, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuage réel vs prédit – modèle avec interactions\n",
    "plt.figure()\n",
    "plt.scatter(y_test_p, y_pred_p)\n",
    "min_v = min(y_test_p.min(), y_pred_p.min())\n",
    "max_v = max(y_test_p.max(), y_pred_p.max())\n",
    "plt.plot([min_v, max_v], [min_v, max_v], linestyle=\"--\")\n",
    "plt.xlabel(\"Valeurs réelles (CPU load)\")\n",
    "plt.ylabel(\"Valeurs prédites\")\n",
    "plt.title(\"Modèle avec interactions (PolynomialFeatures) – Réel vs Prédit\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4a199",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Recommandations\n",
    "- **Interprétation des coefficients** : examiner l’influence de chaque indicateur pour expliquer la charge CPU (utile en SOC).  \n",
    "- **Interactions** : si la performance s’améliore, conserver quelques interactions pertinentes plutôt que toutes (risque de sur‑ajustement).  \n",
    "- **Modèles alternatifs** : tester des approches non linéaires (`KNN`, `RandomForestRegressor`, `XGBoost`).   \n",
    "- **Validation plus robuste** : utiliser une **validation croisée** et un **pipeline** scikit‑learn (scaler + sélection + modèle).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df07c40",
   "metadata": {},
   "source": [
    "## 9) Travail à faire KNN (`KNeighborsRegressor()`)\n",
    "\n",
    "1. Construisez un pipeline complet combinant les étapes suivantes :\n",
    "\n",
    "    - Standardisation des variables d’entrée (`StandardScaler`)\n",
    "    - Génération de caractéristiques non linéaires (`PolynomialFeatures`)\n",
    "    - Sélection automatique de variables (`SequentialFeatureSelector`)\n",
    "    - Modèle final de régression (`KNeighborsRegressor`)\n",
    "\n",
    "2. Définissez ensuite une `grille` d’hyperparamètres  :\n",
    "\n",
    "    - \"n_features_to_select\": [2, 3, 4, 5] # pour tester différents nombres de variables sélectionnées\n",
    "    - \"n_neighbors\": [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "3. Mettez en place un `GridSearchCV` pour identifier la combinaison optimale des hyperparamètres en utilisant la validation croisée et le score R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "base_knn = KNeighborsRegressor()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "        # Génération de features polynomiales\n",
    "    (\"poly\", PolynomialFeatures(\n",
    "        degree=2,\n",
    "        include_bias=False\n",
    "    )),\n",
    "    (\"sfs\", SequentialFeatureSelector(\n",
    "        estimator=base_knn,\n",
    "        n_features_to_select=3,     # valeur par défaut (sera ajustée par la grille)\n",
    "        direction=\"forward\",\n",
    "        scoring=\"r2\",\n",
    "        cv=5\n",
    "    )),\n",
    "    (\"knn\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"sfs__n_features_to_select\": [2, 3, 4, 5],    \n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9, 11, 13, 15],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres :\")\n",
    "print(grid.best_params_)\n",
    "print(\"Meilleur R² (CV) :\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7124ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_best = grid.best_estimator_.named_steps[\"sfs\"]\n",
    "support = sfs_best.get_support()\n",
    "selected_features = X.columns[support]\n",
    "print(\"Features sélectionnées :\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cf125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation test\n",
    "# =========================\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"R² sur test :\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Voir les features sélectionnées par SFS\n",
    "sfs_best = grid.best_estimator_.named_steps[\"sfs\"]\n",
    "support = sfs_best.get_support()\n",
    "print(\"Nombre de features polynomiales sélectionnées :\", support.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bffcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = grid.best_estimator_          # le meilleur pipeline trouvé\n",
    "sfs = best_pipe.named_steps[\"sfs\"]        # étape SFS du pipeline\n",
    "poly = best_pipe.named_steps[\"poly\"]\n",
    "support = sfs.get_support()               # masque booléen des features sélectionnées\n",
    "\n",
    "# X était un DataFrame avec des colonnes nommées\n",
    "original_feature_names = X.columns\n",
    "\n",
    "# Noms des features polynomiales (après PolynomialFeatures)\n",
    "poly_feature_names = poly.get_feature_names_out(original_feature_names)\n",
    "\n",
    "# Appliquer le masque du SFS sur ces noms\n",
    "selected_poly_features = poly_feature_names[support]\n",
    "\n",
    "print(\"Variables retenues dans le modèle :\", selected_poly_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c23c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Résultats du GridSearch\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Extraire n_features_to_select et le mean_test_score\n",
    "n_features = results[\"param_sfs__n_features_to_select\"].astype(int)\n",
    "scores = results[\"mean_test_score\"]\n",
    "\n",
    "plt.plot(n_features, scores, marker=\"o\")\n",
    "plt.xlabel(\"Nombre de variables sélectionnées (n_features_to_select)\")\n",
    "plt.ylabel(\"Score R² moyen (CV)\")\n",
    "plt.title(\"Impact du nombre de variables sur les performances du modèle\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75657ca",
   "metadata": {},
   "source": [
    "En fait, on faisait varier  knn__n_neighbors, donc pour un même n_features_to_select, on a plusieurs lignes dans cv_results_.\n",
    "\n",
    "Pour chaque valeur de n_features_to_select, on prend le meilleur R² parmi toutes les autres combinaisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c275f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# S'assurer que c'est bien des entiers\n",
    "results[\"param_sfs__n_features_to_select\"] = results[\"param_sfs__n_features_to_select\"].astype(int)\n",
    "\n",
    "# Regrouper par n_features_to_select et prendre le meilleur score pour chacun\n",
    "grouped = results.groupby(\"param_sfs__n_features_to_select\")[\"mean_test_score\"].max()\n",
    "\n",
    "# Récupérer x et y\n",
    "n_features = grouped.index.values\n",
    "best_scores = grouped.values\n",
    "\n",
    "plt.plot(n_features, best_scores, marker=\"o\")\n",
    "plt.xlabel(\"Nombre de variables sélectionnées (n_features_to_select)\")\n",
    "plt.ylabel(\"Meilleur score R² moyen (CV)\")\n",
    "plt.title(\"R² (CV) en fonction du nombre de variables sélectionnées\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f727b65",
   "metadata": {},
   "source": [
    "L'écart de performances ontenu par 3 et 5 variables ne semble pas significatif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c2b6e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
